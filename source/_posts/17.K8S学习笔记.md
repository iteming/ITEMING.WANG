---
layout: 
title: 17.K8S学习笔记
date: 2024-04-01 14:10:00
tags:
---

k8s的简介以及搭建
一：简介
1.什么是k8s？
k8s是一个docker容器管理工具
它是一个全新的基于容器技术的分布式架构领先方案，是开源的容器集群管理系统。
在docker的基础上，为容器化的应用提供部署运行，资源调度，服务发现和动态伸缩等一系列完整功能
 
2.----k8s的优势：
a，容器编排
b，轻量级
c，开源
d，弹性伸缩
e，负载均衡
 
二：k8s的核心功能
1.自愈: 重新启动失败的容器，在节点不可用时，替换和重新调度节点上的容器，对用户定义的健康检查不响应的容器会被中止，并且在容器准备好服务之前不会把其向客户端广播。
弹性伸缩: 通过监控容器的cpu的负载值,如果这个平均高于80%,增加容器的数量,如果这个平均低于10%,减少容器的数量
服务的自动发现和负载均衡: 不需要修改您的应用程序来使用不熟悉的服务发现机制，Kubernetes 为容器提供了自己的 IP 地址和一组容器的单个 DNS 名称，并可以在它们之间进行负载均衡。
滚动升级和一键回滚: Kubernetes 逐渐部署对应用程序或其配置的更改，同时监视应用程序运行状况，以确保它不会同时终止所有实例。 如果出现问题，Kubernetes会为您恢复更改，利用日益增长的部署解决方案的生态系统。
 
2.核心概念
（1）master
                    k8s集群的管理节点，负责管理集群，提供集群的资源数据的访问入口
（2）Node
                    node是k8s集群架构中运行pod的服务节点
（3）Pod
                    运行于Node节点上，若干相关容器的组合，pod内包含的容器运行在同一宿主机上，使用相同的网络命名空间，IP地址和端口，能够通过localhost进行通信
 
三：k8s的应用场景
k8s最适合跑微服务架构
 
四：搭建前的准备工作（所有服务器）
1.准备三台linux服务器，每台服务器配置2G内存和2CPU
角色                    主机名                  IP地址
Master                master                  192.168.175.3
Node                   node1                  192.168.175.250
Node                   node2                  192.168.175.251
 
2.安装vim  
命令：yum -y install vim
 
3.更改hosts文件添加主机名与IP映射关系
命令：vim /etc/hosts
192.168.175.3     master
192.168.175.250   node1
192.168.175.251   node2
 
4.关闭防火墙和selinux 
命令：iptables -F              #清除防火墙规则
命令：systemctl stop firewalld              #关闭防火墙
命令：setenforce 0              #关闭selinux
 
四：Kubernetes搭建
1.在各个节点上面安装k8s组件
配置master为etcd和master节点：
命令：[root@master ~]# yum install -y kubernetes etcd flannel ntp
命令：[root@node1 ~]# yum install -y kubernetes etcd flannel ntp
命令：[root@node2 ~]# yum install -y kubernetes etcd flannel ntp
 
2.（1）配置etcd
命令：[root@master ~]# vim /etc/etcd/etcd.conf                  #修改以下配置
ETCD_LISTEN_CLIENT_URLS="http://localhost:2379,http://192.168.175.3:2379"
ETCD_NAME="etcd"
ETCD_ADVERTISE_CLIENT_URLS="http://192.168.175.3:2379"

 
（2）启动服务
命令：[root@master ~]# systemctl start etcd
命令：[root@master ~]# systemctl status etcd
命令：[root@master ~]# systemctl enable etcd

 
 
注意：etcd 通讯使用 2379 端口
（3）查看状态：
命令：[root@master ~]# ss -antulp | grep 2379

 
 
（4）检查 etcd 集群成员列表，这里只有一台
命令：[root@master ~]# etcdctl member list

 
 
 
3.配置master服务器
（1）配置master配置文件
命令：[root@master ~]# vim /etc/kubernetes/config                    #修改以下配置文件
KUBE_MASTER="--master=http://192.168.175.3:8080"

 
 
 
（2）配置apiserver配置文件
命令：[root@master ~]# vim /etc/kubernetes/apiserver
KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"
KUBE_ETCD_SERVERS="--etcd-servers=http://192.168.175.3:2379"
KUBE_ADMISSION_CONTROL="--admission-control=AlwaysAdmit"

 
 
 （3）配置 kube-scheduler 配置文件
命令：[root@master ~]# vim /etc/kubernetes/scheduler
KUBE_SCHEDULER_ARGS="0.0.0.0"

 
 
 
4.（1） 配置 etcd，指定容器云中 docker 的 IP 网段
命令：[root@master ~]# etcdctl mkdir /k8s/network
命令：[root@master ~]# etcdctl set /k8s/network/config '{"Network": "10.255.0.0/16"}'
命令：[root@master ~]# etcdctl get /k8s/network/config

（2）设置flanneld服务
命令：[root@master ~]# vim /etc/sysconfig/flanneld
FLANNEL_ETCD_ENDPOINTS="http://192.168.175.3:2379"
FLANNEL_ETCD_PREFIX="/k8s/network"
FLANNEL_OPTIONS="--iface=ens33"                           #设置自己的通信物理网卡

 
 
命令：[root@master ~]# systemctl restart flanneld         #重启服务
 
（3）检查所有配置
命令：[root@master ~]# cat /run/flannel/subnet.env
FLANNEL_NETWORK=10.255.0.0/16
FLANNEL_SUBNET=10.255.94.1/24
FLANNEL_MTU=1472
FLANNEL_IPMASQ=false

 
命令：[root@master ~]# cat /run/flannel/docker
DOCKER_OPT_BIP="--bip=10.255.94.1/24"
DOCKER_OPT_IPMASQ="--ip-masq=true"
DOCKER_OPT_MTU="--mtu=1472"
DOCKER_NETWORK_OPTIONS=" --bip=10.255.94.1/24 --ip-masq=true --mtu=1472"

 
5. 启动master上4个服务
命令：[root@master ~]# systemctl restart kube-apiserver kube-controller-manager kube-scheduler flanneld
命令：[root@master ~]# systemctl status kube-apiserver kube-controller-manager kube-scheduler flanneld
命令：[root@master ~]# systemctl enable kube-apiserver kube-controller-manager kube-scheduler flanneld
 
6. 配置minion节点服务器
注意：minion各节点配置相同，这边已node1为例
（1）配置flanneld服务
命令：[root@node1 ~]# vim /etc/sysconfig/flanneld
FLANNEL_ETCD_ENDPOINTS="http://192.168.175.3:2379"
FLANNEL_ETCD_PREFIX="/k8s/network"
FLANNEL_OPTIONS="--iface=ens33"

 
（2）命令：[root@node1 ~]# vim  /etc/kubernetes/config
KUBE_MASTER="--master=http://192.168.175.3:8080"

 
（3）命令：[root@node1 ~]# vim /etc/kubernetes/kubelet
KUBELET_ADDRESS="--address=0.0.0.0"
KUBELET_HOSTNAME="--hostname-override=node1"
KUBELET_API_SERVER="--api-servers=http://192.168.175.3:8080"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest"

 
(4)启动node1服务
命令：[root@node1 ~]# systemctl restart flanneld kube-proxy kubelet docker
命令：[root@node1 ~]# systemctl enable flanneld kube-proxy kubelet docker
命令：[root@node1 ~]# systemctl status flanneld kube-proxy kubelet docker

7.查看服务是否安装成功（在master上查看）
命令：[root@master ~]# kubectl get nodes
NAME      STATUS    AGE
node1     Ready     2h
node2     Ready     25s

 
五：Kubernetes的web管理界面搭建
1. 创建dashboard-deployment.yaml配置文件
命令：[root@master ~]# vim /etc/kubernetes/dashboard-deployment.yaml
apiVersion: extensions/v1beta1

kind: Deployment

metadata:

# Keep the name in sync with image version and

# gce/coreos/kube-manifests/addons/dashboard counterparts

  name: kubernetes-dashboard-latest

  namespace: kube-system

spec:

  replicas: 1

  template:

    metadata:

      labels:

        k8s-app: kubernetes-dashboard

        version: latest

        kubernetes.io/cluster-service: "true"

    spec:

      containers:

      - name: kubernetes-dashboard
                                                            
        image: docker.io/bestwu/kubernetes-dashboard-amd64:v1.6.3

        imagePullPolicy: IfNotPresent

        resources:

          # keep request = limit to keep this container in guaranteed class
          limits:

            cpu: 100m

            memory: 50Mi

          requests:

            cpu: 100m

            memory: 50Mi

        ports:

        - containerPort: 9090

        args:

        - --apiserver-host=http://172.26.0.10:8080

        livenessProbe:

          httpGet:

            path: /

            port: 9090

          initialDelaySeconds: 30

          timeoutSeconds: 30


 
2.创建编辑 dashboard-service.yaml 文件：
命令：[root@master ~]# vim /etc/kubernetes/dashboard-service.yaml
apiVersion: v1

kind: Service

metadata:

  name: kubernetes-dashboard

  namespace: kube-system

  labels:

    k8s-app: kubernetes-dashboard

    kubernetes.io/cluster-service: "true"

spec:

  selector:

    k8s-app: kubernetes-dashboard

  ports:

  - port: 80

    targetPort: 9090

 
3.node1和node2需要提前拉取两个镜像
命令：[root@node1 ~]# docker search kubernetes-dashboard-amd
命令：[root@node1 ~]# docker pull docker.io/siriuszg/kubernetes-dashboard-amd64
命令：[root@node1 ~]# docker search pod-infrastructure
命令：[root@node1 ~]# docker pull docker.io/xiaotech/pod-infrastructure
命令：[root@node1 ~]# docker images
REPOSITORY                                      TAG                 IMAGE ID            CREATED             SIZE
docker.io/siriuszg/kubernetes-dashboard-amd64   latest              a8e05b8cb40d        3 months ago        122 MB
docker.io/xiaotech/pod-infrastructure           latest              04ccf7b18fb5        16 months ago       209 MB
命令：[root@node2 ~]# docker images
REPOSITORY                                      TAG                 IMAGE ID            CREATED             SIZE
docker.io/siriuszg/kubernetes-dashboard-amd64   latest              a8e05b8cb40d        3 months ago        122 MB
docker.io/xiaotech/pod-infrastructure           latest              04ccf7b18fb5        16 months ago       209 MB

4. 启劢 dashboard 的 deployment 和 service
命令：[root@master ~]# kubectl create -f /etc/kubernetes/dashboard-deployment.yaml
deployment "kubernetes-dashboard-latest" created

 
命令：[root@master ~]# kubectl create -f /etc/kubernetes/dashboard-service.yaml

 
 
5.查看运行结果
命令：[root@master ~]# kubectl get deployment --all-namespaces

 
命令：[root@master ~]# kubectl get svc --all-namespaces

